{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxrkZWMLZB8z"
      },
      "source": [
        "# Tarea 1: Introducci√≥n, Vector Space Models, Information Retrieval y Language Models</h1>\n",
        "**Procesamiento de Lenguaje Natural (CC6205-1 - Oto√±o 2024)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b97b4IJjZGxM"
      },
      "source": [
        "## Tarjeta de identificaci√≥n\n",
        "\n",
        "**Nombres:**\n",
        "1. Mart√≠n Bravo\n",
        "2. Felipe Fierro\n",
        "\n",
        "**Fecha l√≠mite de entrega üìÜ:** 10/04.\n",
        "\n",
        "**Tiempo estimado de dedicaci√≥n:** 4 horas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKcZMFlmZ3b9"
      },
      "source": [
        "## Instrucciones\n",
        "Bienvenid@s a la primera tarea en el curso de Natural Language Processing (NLP). Esta tarea tiene como objetivo evaluar los contenidos te√≥ricos de las primeras semanas de clases, enfocado principalmente en **Information Retrieval (IR)**, **Vector Space Models** y **Language Models**. Si a√∫n no has visto las clases, se recomienda visitar los links de las referencias.\n",
        "\n",
        "La tarea consta de una parte te√≥rica que busca evaluar conceptos vistos en clases. Seguido por una parte pr√°ctica con el f√≠n de introducirlos a la programaci√≥n en Python enfocada en NLP.\n",
        "\n",
        "* La tarea es en **grupo** (maximo hasta 3 personas).\n",
        "* La entrega es a trav√©s de u-cursos a m√°s tardar el d√≠a estipulado arriba. No se aceptan atrasos.\n",
        "* El formato de entrega es este mismo Jupyter Notebook.\n",
        "* Al momento de la revisi√≥n su c√≥digo ser√° ejecutado. Por favor verifiquen que su entrega no tenga errores de compilaci√≥n.\n",
        "* Completar la tarjeta de identificaci√≥n. Sin ella no podr√° tener nota."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnTrhOKraAw2"
      },
      "source": [
        "## Material de referencia\n",
        "\n",
        "Diapositivas del curso üìÑ\n",
        "    \n",
        "- [Introducci√≥n al curso](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-introduction.pdf)\n",
        "- [Vector Space Model / Information Retrieval](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-IR.pdf)    \n",
        "- [Probabilistic Language Models](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-PLM.pdf)\n",
        "\n",
        "Videos del curso üì∫\n",
        "- Introducci√≥n  [Parte 1](https://www.youtube.com/watch?v=HEKTNOttGvU)  [Parte 2](https://www.youtube.com/watch?v=P8cwnI-f-Kg)\n",
        "\n",
        "- Information Retrieval [Parte 1](https://www.youtube.com/watch?v=FXIVClF370w&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3) [Parte 2](https://www.youtube.com/watch?v=f8nG1EMmPZk&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3)\n",
        "- Probabilistic Language Models [Parte 1](https://www.youtube.com/watch?v=9E2jJ6kcb4Y&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3) [Parte 2](https://www.youtube.com/watch?v=ZWqbEQXLra0&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=5) [Parte 3](https://www.youtube.com/watch?v=tsumFqwFlaA&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=6) [Parte 4](https://www.youtube.com/watch?v=s3TWdv4sqkg&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7w4BT1qmChV"
      },
      "source": [
        "## P1. Tokenizaci√≥n\n",
        "\n",
        "En el primer ejercicio veremos la dificultad de tokenizar textos no estructurados, destacando la importancia de tener librer√≠as que realicen este trabajo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fG0hLbHg9dn"
      },
      "source": [
        "### Pregunta 1.a (0.25 puntos)\n",
        "\n",
        "Dise√±e una funci√≥n **`get_tokens()`** que reciba un texto y entregue una lista con sus tokens. Es libre de elegir la forma de tokenizar mientras no utilice librer√≠as con tokenizadores ya implementados. Puede utilizar la librer√≠a **re** importada para trabajar s√≠mbolos. Explique su razonamiento.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Ya que estamos trabajando el documento de forma local vamos a poner el texto directamente ac√°**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[Letra de \"¬°Oh, Algoritmo!\" ft. Nora Erez]\\n\\n[Refr√°n: Jorge Drexler]\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n\\n[Estribillo: Jorge Drexler]\\nDime qu√© debo cantar\\nOh, algoritmo\\nS√© que lo sabes mejor\\nIncluso que yo mismo\\n\\n[Verso 1: Nora Erez]\\nWait, what\\'s that money that you spent?\\nWhat\\'s that sitting on your plate?\\nDo you want what you\\'ve been fed?\\nAre you the fish or bait?\\nMmm, I\\'m on the top of the roof and I feel like a jail\\nRather not pay the bail\\nTo dangerous people with blood on their faces\\nSo I\\'m sharing a cell with the masses\\nThe underground always strive for the main\\nStreaming like Grande\\'s big-ass ring\\nScreaming: I\\'ll write you out my will\\nConscious is free, but not the will\\nConscious is free, but not the will\\nYou might also like\\nAmor al Arte\\nJorge Drexler\\nTinta y Tiempo\\nJorge Drexler\\nAsilo\\nJorge Drexler\\n[Pre-Estribillo: Nora Erez]\\nSo if you want me to want what I believe that I want\\nCan I choose to quit?\\n\\n[Estribillo: Jorge Drexler]\\nDime qu√© debo cantar\\nOh, algoritmo\\nS√© que lo sabes mejor\\nIncluso que yo mismo\\n\\n[Verso 2: Jorge Drexler]\\nPor ejemplo, esta canci√≥n\\n¬øQu√© algoritmo la pari√≥?\\nMe pregunto si fui yo\\n¬øLa elegiste o te eligi√≥?\\n\\n[Verso 3: Jorge Drexler]\\nDios era la letra chica al final del papel\\nYa no contamos con √âl\\nFin de la Luna de miel\\nY el libre albedr√≠o es un cauce vac√≠o\\nUn barco que no tiene r√≠o\\nNi timonel\\n\\n[Verso 4: Jorge Drexler]\\nTodos aplauden, t√∫ tambi√©n\\nPero no queda claro qui√©n\\nTiene del mango a la sart√©n\\nDel sacrificio\\nPiel o silicio\\nY el precipicio\\nDice: Ven, ven, ven\\n[Refr√°n: Jorge Drexler]\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n(Dime qu√© debo cantar)\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n(Oh, algoritmo)\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n(S√© que lo sabes mejor)\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n(Incluso que yo mismo)\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n(Dime qu√© debo cantar)\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n(Oh, algoritmo)\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n(S√© que lo sabes mejor)\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n(Incluso que yo mismo)\\n¬øQui√©n quiere que yo quiera lo que creo que quiero?\\n(Wow)'"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Abrir oh_algoritmo.txt\n",
        "with open('oh_algoritmo.txt', 'r') as file:\n",
        "    texto = file.read()\n",
        "\n",
        "texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "5P7rk4VRm6Az"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "qiRMkdjwazFT"
      },
      "outputs": [],
      "source": [
        "def get_tokens(text):\n",
        "    \n",
        "\n",
        "    # Reemplazar \\n por espacio\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    # Separar palabras entre corchetes y parentesis\n",
        "    text = re.sub(r'\\[.*?\\]', ' ', text)\n",
        "    text = re.sub(r'\\(.*?\\)', ' ', text)\n",
        "    # Separar signos de puntuaci√≥n, guiones, guiones bajos, comillas y otros\n",
        "    text = re.sub(r'[\\-\\_.,;:!?¬ø¬°\\']', ' ', text)\n",
        "\n",
        "    # Separar palabras\n",
        "    tokens = text.split()\n",
        "    \n",
        "    # Eliminar tokens vac√≠os (en caso de haber espacios adicionales)\n",
        "    tokens = [token for token in tokens if token.strip()]\n",
        "    \n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "hDBZn4kOm7uH",
        "outputId": "aab7c99e-14ef-43b6-c3a5-1184f6aeaf13"
      },
      "outputs": [],
      "source": [
        "tokens = get_tokens(texto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CpZKljrotLa"
      },
      "source": [
        "### Pregunta 1.b (0.25 puntos)\n",
        "Explique su implementaci√≥n aqu√≠:\n",
        "> La implementaci√≥n consiste en todos los saltos de l√≠nea por espacios, luego los corchetes, parentesis y llaves son separados de las palabras, luego se eliminan los signos de puntuaci√≥n y se separan las palabras por espacios. Finalmente se eliminan los espacios en blanco y se retorna una lista con las palabras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIwAKWZvofEp"
      },
      "source": [
        "Implementaci√≥n con la libreria NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GR2Z0lnnPB9",
        "outputId": "65500454-2fbd-4e49-9e45-71fd08a8f6e3"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import wordpunct_tokenize\n",
        "nltk_tokens = wordpunct_tokenize(texto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos verificar las diferencias entre ambos c√≥digos, podemos ver que son muy pocas con respecto al algoritmo de NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set()\n",
            "{')', '1', '4', ':', '\"¬°', '¬ø', ',', '!\"', 'Erez', \"'\", '-', '3', 'Refr√°n', '[', '2', 'Letra', 'Algoritmo', 'Pre', 'ft', 'Wow', '?', ']', 'Nora', 'Estribillo', '.', '(', 'Verso'}\n"
          ]
        }
      ],
      "source": [
        "print(set(tokens) - set(nltk_tokens))\n",
        "print(set(nltk_tokens) - set(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so3P4OeGn-qo"
      },
      "source": [
        "### Pregunta 1.c (0.5 puntos)\n",
        "¬øQu√© diferencias y similitudes encontrase al comparar la funci√≥n de tokenizaci√≥n creada manualmente por ti contra la implementaci√≥n de NLTK, al tokenizar la letra de la canci√≥n \"Oh, algoritmo\"?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E12BZ29JoFCp"
      },
      "source": [
        "> Algunas diferencias que se pueden encontrar son que la implementaci√≥n manual no considera los signos de puntuaci√≥n como tokens, mientras que la implementaci√≥n de NLTK si lo hace. Por otro lado, ambas implementaciones consideran los saltos de l√≠nea como espacios, y eliminan los espacios en blanco al final de cada token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmUULnB6hWcl"
      },
      "source": [
        "## P2. Stemming y Stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LskhxOLdpT9q"
      },
      "source": [
        "En esta secci√≥n debera implementar funciones de stemming y stopwords basado en lo visto en clase. En la siguiente celda tiene el corpus que usara en esta secci√≥n:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "hj07_CmwhYxk"
      },
      "outputs": [],
      "source": [
        "# Corpus en espa√±ol\n",
        "corpus_espanol = [\n",
        "    \"¬øQui√©n quiere que yo quiera lo que creo que quiero?\",\n",
        "    \"Dime qu√© debo cantar\",\n",
        "    \"S√© que lo sabes mejor\"\n",
        "]\n",
        "\n",
        "# Corpus en ingl√©s\n",
        "corpus_ingles = [\n",
        "    \"What's that sitting on your plate?\",\n",
        "    \"Do you want what you've been fed?\",\n",
        "    \"Are you the fish or bait?\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xRyOVbVWwJ5"
      },
      "source": [
        "### Pregunta 2.a (0.5 puntos)\n",
        "Implemente una funci√≥n **`get_vocab()`** que extraiga los tokens de un corpus. Puede utilizar la funci√≥n de la secci√≥n anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "F-727zL3ptDZ"
      },
      "outputs": [],
      "source": [
        "def get_vocab(corpus):\n",
        "\n",
        "  corpus_complete = \"\"\n",
        "  for i in range(len(corpus)):\n",
        "    corpus_complete += corpus[i] + \" \"\n",
        "  tokens = get_tokens(corpus_complete)\n",
        "  return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge2cPS7fqYXy",
        "outputId": "2b5f148c-15cc-461a-c12e-ca9562f2639e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Obtenemos el vocabulario del corpus en espa√±ol\n",
        "vocab_espanol = get_vocab(corpus_espanol)\n",
        "\n",
        "# Comprobamos que el vocabulario obtenido es correcto\n",
        "set(['yo', 'debo', 'creo', 'Dime', 'lo', 'cantar', 'mejor', 'S√©', 'que', 'quiere', 'quiero', 'sabes', 'Qui√©n', 'quiera', 'qu√©']) == set(vocab_espanol) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCFtzHUbzJqt"
      },
      "source": [
        "Resultado esperado (el orden puede variar):\n",
        "```\n",
        "['yo', 'debo', 'creo', 'Dime', 'lo', 'cantar', 'mejor', 'S√©', 'que', 'quiere', 'quiero', 'sabes', 'Qui√©n', 'quiera', 'qu√©']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apRK_d8uqlSm",
        "outputId": "b6460bf1-b8bf-471b-e97f-1789e7367348"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Obtenemos el vocabulario del corpus en ingl√©s\n",
        "vocab_ingles = get_vocab(corpus_ingles)\n",
        "\n",
        "# Comprobamos que el vocabulario obtenido es correcto\n",
        "set(vocab_ingles) == set(['fed', 'been', 'or', 'want', 'plate', 'the', 've', 'your', 's', 'you', 'what', 'Are', 'bait', 'What', 'fish', 'that', 'sitting', 'Do', 'on'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvWMUQq5zPP8"
      },
      "source": [
        "Resultado esperado:\n",
        "```\n",
        "['fed', 'been', 'or', 'want', 'plate', 'the', 've', 'your', 's', 'you', 'what', 'Are', 'bait', 'What', 'fish', 'that', 'sitting', 'Do', 'on']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FVjU3cAzDkw"
      },
      "source": [
        "### Pregunta 2.b (0.5 puntos)\n",
        "Ahora dise√±e reglas que usted estime convenientes tanto de **Stemming** como de **Stopwords**. Implemente una funci√≥n que reciba una lista con los elementos del vocabulario, le aplique sus reglas y devuelva el vocabulario preprocesado. Explique las reglas de stemming y elecci√≥n de stopwords:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZSeU-rDYbI1"
      },
      "source": [
        "    Explique sus reglas aqu√≠:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Primero definimos los sufijos de los que nos queremos deshacer para hacer el stemming, luego definimos las stopwords que queremos eliminar del vocabulario.\n",
        "\n",
        "Luego pasamos todas las palabras a min√∫sculas eliminando las tildes, finalmente eliminamos los sufijos definidos y las stopwords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "777xbIG2sqy5"
      },
      "outputs": [],
      "source": [
        "def pre_processing(vocabulario, idioma):\n",
        "\n",
        "    # Definimos los sufijos de los cuales queremos deshacernos\n",
        "    stemming = {\n",
        "        \"espanol\": [\"ar\", \"er\", \"ir\", \"a\", \"e\", \"o\", \"s\", \"es\"],\n",
        "        \"ingles\": [\"s\", \"es\", \"ed\", \"ing\", \"ly\", \"er\", \"est\", \"ing\"]\n",
        "    }\n",
        "\n",
        "    # Definimos las palabras que queremos eliminar\n",
        "    stopwords = {\n",
        "        \"espanol\": [\"yo\", \"lo\", \"que\", \"qu√©\", \"debo\", \"S√©\"],\n",
        "        \"ingles\": [\"or\", \"the\", \"ve\", \"s\", \"what\", \"are\", \"Are\", \"that\", \"What\", \"Do\", \"on\", \"been\", \"you\", \"your\", \"fed\"]\n",
        "    }            \n",
        "\n",
        "    # Creamos una copia del vocabulario\n",
        "    new_vocab = vocabulario.copy()\n",
        "\n",
        "    # Convertimos todas las palabras a min√∫sculas\n",
        "    new_vocab = [palabra.lower() for palabra in new_vocab]\n",
        "\n",
        "    # Eliminar tilde\n",
        "    new_vocab = [palabra.replace(\"√°\", \"a\").replace(\"√©\", \"e\").replace(\"√≠\", \"i\").replace(\"√≥\", \"o\").replace(\"√∫\", \"u\") for palabra in new_vocab]\n",
        "\n",
        "    # Eliminar sufijos y stopwords\n",
        "    for palabra in range(len(new_vocab)):\n",
        "        for sufijo in stemming[idioma]:\n",
        "            if new_vocab[palabra].endswith(sufijo):\n",
        "                new_vocab[palabra] = new_vocab[palabra][:-len(sufijo)]\n",
        "        if new_vocab[palabra] in stopwords[idioma]:\n",
        "            new_vocab[palabra] = \"\"\n",
        "\n",
        "    new_vocab = [palabra for palabra in new_vocab if palabra]\n",
        "\n",
        "    return set(new_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT1Rr0das2Nb",
        "outputId": "503fd5f8-ee46-4367-bee1-f85fb24cea03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulario procesado en espa√±ol: {'cant', 'sabe', 'l', 'deb', 'quier', 'y', 'mejor', 'qu', 'cre', 'quien', 'dim'} \n",
            "\n",
            "Vocabulario procesado en ingl√©s: {'f', 'do', 'fish', 'sitt', 'plate', 'want', 'bait'} \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Aplicar preprocesamiento a los vocabularios de ejemplo con NLTK\n",
        "vocab_procesado_espanol = pre_processing(vocab_espanol, 'espanol')\n",
        "vocab_procesado_ingles = pre_processing(vocab_ingles, 'ingles')\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Vocabulario procesado en espa√±ol:\", vocab_procesado_espanol, \"\\n\")\n",
        "print(\"Vocabulario procesado en ingl√©s:\", vocab_procesado_ingles, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajmn1HaNhZE9"
      },
      "source": [
        "## P3. Bag of Words (0.5 puntos)\n",
        "Considere el siguiente corpus, donde cada elemento del arreglo representa un documento:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "vT0XQM2Ghlvy"
      },
      "outputs": [],
      "source": [
        "d0 = 'El p√°jaro come semillas'\n",
        "d1 = 'El p√°jaro se despierta y canta'\n",
        "d2 = 'El p√°jaro canta y come semillas'\n",
        "d3 = 'El pez come y nada en el agua'\n",
        "d4 = 'El pez empieza a nadar'\n",
        "d5 = 'El pez come alimento'\n",
        "corpus = [d0, d1, d2, d3, d4, d5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeOOz1Su2ATf"
      },
      "source": [
        "El objetivo da las siguientes secciones es determinar cu√°les de  los documentos entregados son los m√°s similares entre s√≠. Para ello utilizaremos la t√©cnica **TF-IDF**.\n",
        "\n",
        "Como los algoritmos de Machine Learning no comprenden el texto en lenguaje natural, estos documentos deben ser convertidos a vectores num√©ricos. La representaci√≥n m√°s simple vista en clases es la de **Bag of Words**, m√©todo mediante el cual se cuentan las apariciones de cada palabra en cada uno de los documentos entregados.\n",
        "\n",
        "Implemente la funci√≥n **`bag_of_words()`**, que recibe como input un arreglo de documentos y devuelve un dataframe de pandas con la representaci√≥n Bag of Words de los documentos entregados. En esta representaci√≥n las columnas son el vocabulario y las filas representan las apariciones de cada una de las palabras en los documentos. En otras palabras, cada fila representa el BoW de un documento.\n",
        "\n",
        "***Disclaimer: el orden de los resultados pueden variar.***\n",
        "\n",
        "\n",
        "Por ejemplo para el siguiente corpus:\n",
        "\n",
        "```\n",
        "corpus = ['El perro ladra', 'El perro come']\n",
        "```\n",
        "\n",
        "Debiese entregarnos lo siguiente:\n",
        "\n",
        "\n",
        "|   | el | perro | ladra | come |\n",
        "|---|----|-------|------|-------|\n",
        "| 0 | 1  | 1     | 1    | 0     |\n",
        "| 1 | 1  | 1     | 0    | 1     |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "_njmcRPM2GpV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MENCbDO8s_ls"
      },
      "source": [
        "Implementar funci√≥n `bag_of_words()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "C_eRRUvD2ChD"
      },
      "outputs": [],
      "source": [
        "def bag_of_words(corpus):\n",
        "    \n",
        "    # Obtener el vocabulario del corpus\n",
        "    vocab = list(set(get_vocab(corpus)))\n",
        "\n",
        "    # Crear un DataFrame con las palabras del vocabulario como columnas\n",
        "    df = pd.DataFrame(columns=vocab, index=range(len(corpus)))\n",
        "\n",
        "    # Llenar el DataFrame con ceros\n",
        "    df = df.fillna(0)\n",
        "\n",
        "    # Recorrer los documentos del corpus\n",
        "    for i in range(len(corpus)):\n",
        "        # Obtener los tokens del documento\n",
        "        tokens = get_tokens(corpus[i])\n",
        "        # Recorrer las palabras del vocabulario\n",
        "        for palabra in vocab:\n",
        "            # Contar cu√°ntas veces aparece la palabra en el documento\n",
        "            df.loc[i, palabra] = tokens.count(palabra)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "jWZyXGra2FOw",
        "outputId": "1b5d13ff-96c7-49c9-e400-c12441976874"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>se</th>\n",
              "      <th>pez</th>\n",
              "      <th>El</th>\n",
              "      <th>p√°jaro</th>\n",
              "      <th>en</th>\n",
              "      <th>nada</th>\n",
              "      <th>alimento</th>\n",
              "      <th>y</th>\n",
              "      <th>nadar</th>\n",
              "      <th>empieza</th>\n",
              "      <th>semillas</th>\n",
              "      <th>canta</th>\n",
              "      <th>come</th>\n",
              "      <th>despierta</th>\n",
              "      <th>el</th>\n",
              "      <th>agua</th>\n",
              "      <th>a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   se  pez  El  p√°jaro  en  nada  alimento  y  nadar  empieza  semillas  \\\n",
              "0   0    0   1       1   0     0         0  0      0        0         1   \n",
              "1   1    0   1       1   0     0         0  1      0        0         0   \n",
              "2   0    0   1       1   0     0         0  1      0        0         1   \n",
              "3   0    1   1       0   1     1         0  1      0        0         0   \n",
              "4   0    1   1       0   0     0         0  0      1        1         0   \n",
              "5   0    1   1       0   0     0         1  0      0        0         0   \n",
              "\n",
              "   canta  come  despierta  el  agua  a  \n",
              "0      0     1          0   0     0  0  \n",
              "1      1     0          1   0     0  0  \n",
              "2      1     1          0   0     0  0  \n",
              "3      0     1          0   1     1  0  \n",
              "4      0     0          0   0     0  1  \n",
              "5      0     1          0   0     0  0  "
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_bow = bag_of_words(corpus)\n",
        "\n",
        "dataset_bow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qEA2Ic2sLlh"
      },
      "source": [
        "Soluci√≥n esperada:\n",
        "\n",
        "|    |   El |   p√°jaro |   despierta |   el |   come |   a |   nadar |   se |   en |   y |   alimento |   semillas |   pez |   empieza |   canta |   agua |   nada |\n",
        "|:---|-----:|---------:|------------:|-----:|-------:|----:|--------:|-----:|-----:|----:|-----------:|-----------:|------:|----------:|--------:|-------:|-------:|\n",
        "| d0 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          0 |          1 |     0 |         0 |       0 |      0 |      0 |\n",
        "| d1 |    1 |        1 |           1 |    0 |      0 |   0 |       0 |    1 |    0 |   1 |          0 |          0 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d2 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   1 |          0 |          1 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d3 |    1 |        0 |           0 |    1 |      1 |   0 |       0 |    0 |    1 |   1 |          0 |          0 |     1 |         0 |       0 |      1 |      1 |\n",
        "| d4 |    1 |        0 |           0 |    0 |      0 |   1 |       1 |    0 |    0 |   0 |          0 |          0 |     1 |         1 |       0 |      0 |      0 |\n",
        "| d5 |    1 |        0 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          1 |          0 |     1 |         0 |       0 |      0 |      0 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMv3UZdRhgqT"
      },
      "source": [
        "## P4. TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oxW5CZjhoE9"
      },
      "source": [
        "### 4.a TF (0.25 puntos)\n",
        "\n",
        "Ahora debemos usar el dataframe del ejercicio anterior para calcular la matriz de TF normalizada por la m√°xima frecuencia $\\max_i({\\text{tf}_{i,j}})$, donde\n",
        "$i$ corresponde al √≠ndice de las filas (BoW) y $j$ al de las columnas (palabras). Es decir, dividir cada BoW sobre la cantidad de veces de la palabra que aparezca m√°s veces en ese vector.\n",
        "\n",
        "\n",
        "$$\\text{nft}_{i,j} = \\frac{\\text{tf}_{i,j}}{\\max_i({\\text{tf}_{i,j})}}$$\n",
        "\n",
        "Implemente la funci√≥n `calc_tf(dataset_bow)`, que entrega la matriz de TF normalizada del BoW del dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "qQhnJuuShmR5"
      },
      "outputs": [],
      "source": [
        "def calc_tf(df):\n",
        "    \n",
        "    # Crear un DataFrame para almacenar los valores de TF\n",
        "    tf = pd.DataFrame(columns=df.columns, index=range(len(df)))\n",
        "\n",
        "    # Recorrer las filas\n",
        "    for i in range(len(df)):\n",
        "        # Calcular el m√°xima de la fila\n",
        "        max = df.loc[i].max()\n",
        "        # Calcular el TF para cada palabra\n",
        "        for palabra in df.columns:\n",
        "            tf.loc[i, palabra] = df.loc[i, palabra] / max\n",
        "\n",
        "    return tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "urDKFQVu2p3V",
        "outputId": "e26338b6-05e9-423f-afca-9fc621ebccd3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>se</th>\n",
              "      <th>pez</th>\n",
              "      <th>El</th>\n",
              "      <th>p√°jaro</th>\n",
              "      <th>en</th>\n",
              "      <th>nada</th>\n",
              "      <th>alimento</th>\n",
              "      <th>y</th>\n",
              "      <th>nadar</th>\n",
              "      <th>empieza</th>\n",
              "      <th>semillas</th>\n",
              "      <th>canta</th>\n",
              "      <th>come</th>\n",
              "      <th>despierta</th>\n",
              "      <th>el</th>\n",
              "      <th>agua</th>\n",
              "      <th>a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    se  pez   El p√°jaro   en nada alimento    y nadar empieza semillas canta  \\\n",
              "0  0.0  0.0  1.0    1.0  0.0  0.0      0.0  0.0   0.0     0.0      1.0   0.0   \n",
              "1  1.0  0.0  1.0    1.0  0.0  0.0      0.0  1.0   0.0     0.0      0.0   1.0   \n",
              "2  0.0  0.0  1.0    1.0  0.0  0.0      0.0  1.0   0.0     0.0      1.0   1.0   \n",
              "3  0.0  1.0  1.0    0.0  1.0  1.0      0.0  1.0   0.0     0.0      0.0   0.0   \n",
              "4  0.0  1.0  1.0    0.0  0.0  0.0      0.0  0.0   1.0     1.0      0.0   0.0   \n",
              "5  0.0  1.0  1.0    0.0  0.0  0.0      1.0  0.0   0.0     0.0      0.0   0.0   \n",
              "\n",
              "  come despierta   el agua    a  \n",
              "0  1.0       0.0  0.0  0.0  0.0  \n",
              "1  0.0       1.0  0.0  0.0  0.0  \n",
              "2  1.0       0.0  0.0  0.0  0.0  \n",
              "3  1.0       0.0  1.0  1.0  0.0  \n",
              "4  0.0       0.0  0.0  0.0  1.0  \n",
              "5  1.0       0.0  0.0  0.0  0.0  "
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf = calc_tf(dataset_bow)\n",
        "tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Swo3ZjwVtZlq"
      },
      "source": [
        "Soluci√≥n esperada:\n",
        "\n",
        "|    |   El |   p√°jaro |   despierta |   el |   come |   a |   nadar |   se |   en |   y |   alimento |   semillas |   pez |   empieza |   canta |   agua |   nada |\n",
        "|:---|-----:|---------:|------------:|-----:|-------:|----:|--------:|-----:|-----:|----:|-----------:|-----------:|------:|----------:|--------:|-------:|-------:|\n",
        "| d0 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          0 |          1 |     0 |         0 |       0 |      0 |      0 |\n",
        "| d1 |    1 |        1 |           1 |    0 |      0 |   0 |       0 |    1 |    0 |   1 |          0 |          0 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d2 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   1 |          0 |          1 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d3 |    1 |        0 |           0 |    1 |      1 |   0 |       0 |    0 |    1 |   1 |          0 |          0 |     1 |         0 |       0 |      1 |      1 |\n",
        "| d4 |    1 |        0 |           0 |    0 |      0 |   1 |       1 |    0 |    0 |   0 |          0 |          0 |     1 |         1 |       0 |      0 |      0 |\n",
        "| d5 |    1 |        0 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          1 |          0 |     1 |         0 |       0 |      0 |      0 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh2bFyHFhpbM"
      },
      "source": [
        "### 4.b IDF (0.5 puntos)\n",
        "\n",
        "Implementar `calc_idf(dataset_bow)`. √âsta debe retornar un diccionario en donde las llaves sean las palabras y los valores sean el c√°lculo de cada idf por palabra.\n",
        "\n",
        "Recordar que $\\text{idf}_{t_i} = \\log_{10}\\frac{N}{n_i}$ con $N = $ n√∫mero de documentos y $n_i = $ n√∫mero de documentos que contienen la palabra $t_i$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "tGLjlSY02usu"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "qoU4AIrm2sDT"
      },
      "outputs": [],
      "source": [
        "def calc_idf(dataset_bow):\n",
        "    \n",
        "    # Crear un diccionario para almacenar los valores de IDF\n",
        "    idf = {}\n",
        "\n",
        "    # N√∫mero de documentos\n",
        "    N = len(dataset_bow)\n",
        "\n",
        "    # Recorrer columnas\n",
        "    for i in range(len(dataset_bow.columns)):\n",
        "        # Calcular la suma de todos los elementos de la columna\n",
        "        n_i = dataset_bow[dataset_bow.columns[i]].sum()\n",
        "\n",
        "        # Calcular el IDF para la palabra i\n",
        "        idf[dataset_bow.columns[i]] = np.log10(N / n_i)\n",
        "\n",
        "    return idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXPErPdw2uQx",
        "outputId": "6f4076e5-79e5-4d21-d233-913c3a47adab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'se': 0.7781512503836436,\n",
              " 'pez': 0.3010299956639812,\n",
              " 'El': 0.0,\n",
              " 'p√°jaro': 0.3010299956639812,\n",
              " 'en': 0.7781512503836436,\n",
              " 'nada': 0.7781512503836436,\n",
              " 'alimento': 0.7781512503836436,\n",
              " 'y': 0.3010299956639812,\n",
              " 'nadar': 0.7781512503836436,\n",
              " 'empieza': 0.7781512503836436,\n",
              " 'semillas': 0.47712125471966244,\n",
              " 'canta': 0.47712125471966244,\n",
              " 'come': 0.17609125905568124,\n",
              " 'despierta': 0.7781512503836436,\n",
              " 'el': 0.7781512503836436,\n",
              " 'agua': 0.7781512503836436,\n",
              " 'a': 0.7781512503836436}"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idf = calc_idf(dataset_bow)\n",
        "idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmp5lXdquAD1"
      },
      "source": [
        "Soluci√≥n esperada:\n",
        "```\n",
        "{'El': 0.0,\n",
        " 'p√°jaro': 0.3010299956639812,\n",
        " 'despierta': 0.7781512503836436,\n",
        " 'el': 0.7781512503836436,\n",
        " 'come': 0.17609125905568124,\n",
        " 'a': 0.7781512503836436,\n",
        " 'nadar': 0.7781512503836436,\n",
        " 'se': 0.7781512503836436,\n",
        " 'en': 0.7781512503836436,\n",
        " 'y': 0.3010299956639812,\n",
        " 'alimento': 0.7781512503836436,\n",
        " 'semillas': 0.47712125471966244,\n",
        " 'pez': 0.3010299956639812,\n",
        " 'empieza': 0.7781512503836436,\n",
        " 'canta': 0.47712125471966244,\n",
        " 'agua': 0.7781512503836436,\n",
        " 'nada': 0.7781512503836436}\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC-_vwiV20XL"
      },
      "source": [
        "### 4.c TF-IDF (0.25 puntos)\n",
        "Programe la funci√≥n `calc_tf_idf(tf, idf)` que entrega el dataframe TF-IDF asociado al dataset que estamos analizando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "004IuUyt23_6"
      },
      "outputs": [],
      "source": [
        "def calc_tf_idf(tf, idf):\n",
        "    \n",
        "    # Crear un DataFrame para almacenar los valores de TF-IDF\n",
        "    tf_idf = pd.DataFrame(columns=tf.columns, index=range(len(tf)))\n",
        "\n",
        "    # Recorrer las filas\n",
        "    for i in range(len(tf)):\n",
        "        # Calcular el TF-IDF para cada palabra\n",
        "        for palabra in tf.columns:\n",
        "            tf_idf.loc[i, palabra] = tf.loc[i, palabra] * idf[palabra]\n",
        "\n",
        "    return tf_idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "KXjP0S3626dw",
        "outputId": "34863c23-c513-4556-d500-5a8e0141d8f8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>se</th>\n",
              "      <th>pez</th>\n",
              "      <th>El</th>\n",
              "      <th>p√°jaro</th>\n",
              "      <th>en</th>\n",
              "      <th>nada</th>\n",
              "      <th>alimento</th>\n",
              "      <th>y</th>\n",
              "      <th>nadar</th>\n",
              "      <th>empieza</th>\n",
              "      <th>semillas</th>\n",
              "      <th>canta</th>\n",
              "      <th>come</th>\n",
              "      <th>despierta</th>\n",
              "      <th>el</th>\n",
              "      <th>agua</th>\n",
              "      <th>a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         se      pez   El   p√°jaro        en      nada  alimento        y  \\\n",
              "0       0.0      0.0  0.0  0.30103       0.0       0.0       0.0      0.0   \n",
              "1  0.778151      0.0  0.0  0.30103       0.0       0.0       0.0  0.30103   \n",
              "2       0.0      0.0  0.0  0.30103       0.0       0.0       0.0  0.30103   \n",
              "3       0.0  0.30103  0.0      0.0  0.778151  0.778151       0.0  0.30103   \n",
              "4       0.0  0.30103  0.0      0.0       0.0       0.0       0.0      0.0   \n",
              "5       0.0  0.30103  0.0      0.0       0.0       0.0  0.778151      0.0   \n",
              "\n",
              "      nadar   empieza  semillas     canta      come despierta        el  \\\n",
              "0       0.0       0.0  0.477121       0.0  0.176091       0.0       0.0   \n",
              "1       0.0       0.0       0.0  0.477121       0.0  0.778151       0.0   \n",
              "2       0.0       0.0  0.477121  0.477121  0.176091       0.0       0.0   \n",
              "3       0.0       0.0       0.0       0.0  0.176091       0.0  0.778151   \n",
              "4  0.778151  0.778151       0.0       0.0       0.0       0.0       0.0   \n",
              "5       0.0       0.0       0.0       0.0  0.176091       0.0       0.0   \n",
              "\n",
              "       agua         a  \n",
              "0       0.0       0.0  \n",
              "1       0.0       0.0  \n",
              "2       0.0       0.0  \n",
              "3  0.778151       0.0  \n",
              "4       0.0  0.778151  \n",
              "5       0.0       0.0  "
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_idf = calc_tf_idf(tf, idf)\n",
        "tf_idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNTa32IsuLWl"
      },
      "source": [
        "Soluci√≥n esperada:\n",
        "\n",
        "|    |   El |   p√°jaro |   despierta |       el |     come |        a |    nadar |       se |       en |       y |   alimento |   semillas |     pez |   empieza |    canta |     agua |     nada |\n",
        "|:---|-----:|---------:|------------:|---------:|---------:|---------:|---------:|---------:|---------:|--------:|-----------:|-----------:|--------:|----------:|---------:|---------:|---------:|\n",
        "| d0 |    0 |  0.30103 |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0       |   0        |   0.477121 | 0       |  0        | 0        | 0        | 0        |\n",
        "| d1 |    0 |  0.30103 |    0.778151 | 0        | 0        | 0        | 0        | 0.778151 | 0        | 0.30103 |   0        |   0        | 0       |  0        | 0.477121 | 0        | 0        |\n",
        "| d2 |    0 |  0.30103 |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0.30103 |   0        |   0.477121 | 0       |  0        | 0.477121 | 0        | 0        |\n",
        "| d3 |    0 |  0       |    0        | 0.778151 | 0.176091 | 0        | 0        | 0        | 0.778151 | 0.30103 |   0        |   0        | 0.30103 |  0        | 0        | 0.778151 | 0.778151 |\n",
        "| d4 |    0 |  0       |    0        | 0        | 0        | 0.778151 | 0.778151 | 0        | 0        | 0       |   0        |   0        | 0.30103 |  0.778151 | 0        | 0        | 0        |\n",
        "| d5 |    0 |  0       |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0       |   0.778151 |   0        | 0.30103 |  0        | 0        | 0        | 0        |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8sQEjVshjQ7"
      },
      "source": [
        "## P5. Cosine-similarity (0.25 puntos)\n",
        "Ahora que tenemos el dataframe de TF-IDF, nos queda calcular la similitud coseno entre todos los vectores. Notar que la matriz resultante ser√° una matriz sim√©trica.\n",
        "\n",
        "Implemente la funci√≥n *cosine_similarity(v1, v2)* que recibe dos vectores (v1 y v2) y calcula la similitud coseno entre ambos. Concluya cu√°les son los dos documentos m√°s similares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "_68mo-BLhmuV"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(v1, v2):\n",
        "\n",
        "    # Calcular el producto punto de los vectores\n",
        "    dot_product = np.dot(v1, v2)\n",
        "\n",
        "    # Calcular la norma de los vectores\n",
        "    norm_v1 = np.linalg.norm(v1)\n",
        "    norm_v2 = np.linalg.norm(v2)\n",
        "\n",
        "    # Calcular la similitud coseno\n",
        "    similarity = dot_product / (norm_v1 * norm_v2)\n",
        "\n",
        "    return similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5z-23CN2_lU",
        "outputId": "6798f54e-69dc-40c6-ca35-d2d4995fe168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El p√°jaro come semillas\n",
            "> Mas similar: El p√°jaro canta y come semillas\n",
            "> Similitud: 0.7233435041520413 \n",
            "\n",
            "El p√°jaro se despierta y canta\n",
            "> Mas similar: El p√°jaro canta y come semillas\n",
            "> Similitud: 0.3932010182312894 \n",
            "\n",
            "El p√°jaro canta y come semillas\n",
            "> Mas similar: El p√°jaro come semillas\n",
            "> Similitud: 0.7233435041520413 \n",
            "\n",
            "El pez come y nada en el agua\n",
            "> Mas similar: El p√°jaro canta y come semillas\n",
            "> Similitud: 0.09171890791406166 \n",
            "\n",
            "El pez empieza a nadar\n",
            "> Mas similar: El pez come alimento\n",
            "> Similitud: 0.07695078406752713 \n",
            "\n",
            "El pez come alimento\n",
            "> Mas similar: El pez come y nada en el agua\n",
            "> Similitud: 0.0878790037217323 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "similarity_matrix = np.zeros((6,6))\n",
        "for i, v1 in enumerate(tf_idf.index.values):\n",
        "  for j, v2 in enumerate(tf_idf.index.values):\n",
        "      similarity = cosine_similarity(tf_idf.loc[v1].values, tf_idf.loc[v2].values)\n",
        "      similarity_matrix[i][j] = similarity\n",
        "\n",
        "for i in range(6):\n",
        "  mask = [k != i for k in range(6)]\n",
        "  j = np.argmax(similarity_matrix[i][mask])\n",
        "\n",
        "  print(corpus[i])\n",
        "  print(\"> Mas similar:\", np.array(corpus)[mask][j])\n",
        "  print(\"> Similitud:\", similarity_matrix[i][mask][j], \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71oH4JHXulGQ"
      },
      "source": [
        "Soluci√≥n esperada:\n",
        "```\n",
        "El p√°jaro come semillas\n",
        "> Mas similar: El p√°jaro canta y come semillas\n",
        "> Similitud: 0.7233435041520414\n",
        "\n",
        "El p√°jaro se despierta y canta\n",
        "> Mas similar: El p√°jaro canta y come semillas\n",
        "> Similitud: 0.39320101823128945\n",
        "\n",
        "El p√°jaro canta y come semillas\n",
        "> Mas similar: El p√°jaro come semillas\n",
        "> Similitud: 0.7233435041520414\n",
        "\n",
        "El pez come y nada en el agua\n",
        "> Mas similar: El p√°jaro canta y come semillas\n",
        "> Similitud: 0.09171890791406168\n",
        "\n",
        "El pez empieza a nadar\n",
        "> Mas similar: El pez come alimento\n",
        "> Similitud: 0.07695078406752713\n",
        "\n",
        "El pez come alimento\n",
        "> Mas similar: El pez come y nada en el agua\n",
        "> Similitud: 0.0878790037217323\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDZln45jfjMf"
      },
      "source": [
        "## P6 N-gramas (0.75 punto)\n",
        "\n",
        "En esta secci√≥n debera determinar los n-gramas del la cancion \"Oh algoritmo\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7duKoBvlSgg"
      },
      "source": [
        "### 6.a Corpus de entrenamiento y test (0.25 puntos)\n",
        "\n",
        "En esta subsecci√≥n debera definir el conjunto de entrenamiento y test de un corpus. Eliga una particion del 80% y 20% del texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juDVurFfl3eZ",
        "outputId": "4c6398a1-ed7b-45ed-cdf7-c5fcd6ffb4c1"
      },
      "outputs": [],
      "source": [
        "# Abrir oh_algoritmo.txt\n",
        "with open('oh_algoritmo.txt', 'r') as file:\n",
        "    texto = file.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYCw0AqOmlzD"
      },
      "source": [
        "Defina una funcion `get_sentences()` que entregue todas las oraciones del corpus que contengan al menos una palabra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "C88f9aVil9d_"
      },
      "outputs": [],
      "source": [
        "def get_sentences(texto):\n",
        "\n",
        "  texto_copy = texto\n",
        "  \n",
        "  # Reemplazar saltos de l√≠nea por puntos\n",
        "  texto_copy = texto_copy.replace(\"\\n\", \".\")\n",
        "  # Separar oraciones\n",
        "  sentences = texto_copy.split(\".\")\n",
        "  # Eliminar oraciones vac√≠as\n",
        "  sentences = [sentence for sentence in sentences if sentence.strip()]\n",
        "  # Juntar 2 primeras (Caso Borde)\n",
        "  sentences = [sentences[0] + sentences[1]] + sentences[2:]\n",
        "  \n",
        "  return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbZ8EhgHmR2c",
        "outputId": "c4b6502e-889a-4339-ee58-1b427867c405"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[Letra de \"¬°Oh, Algoritmo!\" ft Nora Erez]',\n",
              " '[Refr√°n: Jorge Drexler]',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '[Estribillo: Jorge Drexler]',\n",
              " 'Dime qu√© debo cantar',\n",
              " 'Oh, algoritmo',\n",
              " 'S√© que lo sabes mejor',\n",
              " 'Incluso que yo mismo',\n",
              " '[Verso 1: Nora Erez]',\n",
              " \"Wait, what's that money that you spent?\",\n",
              " \"What's that sitting on your plate?\",\n",
              " \"Do you want what you've been fed?\",\n",
              " 'Are you the fish or bait?',\n",
              " \"Mmm, I'm on the top of the roof and I feel like a jail\",\n",
              " 'Rather not pay the bail',\n",
              " 'To dangerous people with blood on their faces',\n",
              " \"So I'm sharing a cell with the masses\",\n",
              " 'The underground always strive for the main',\n",
              " \"Streaming like Grande's big-ass ring\",\n",
              " \"Screaming: I'll write you out my will\",\n",
              " 'Conscious is free, but not the will',\n",
              " 'Conscious is free, but not the will',\n",
              " 'You might also like',\n",
              " 'Amor al Arte',\n",
              " 'Jorge Drexler',\n",
              " 'Tinta y Tiempo',\n",
              " 'Jorge Drexler',\n",
              " 'Asilo',\n",
              " 'Jorge Drexler',\n",
              " '[Pre-Estribillo: Nora Erez]',\n",
              " 'So if you want me to want what I believe that I want',\n",
              " 'Can I choose to quit?',\n",
              " '[Estribillo: Jorge Drexler]',\n",
              " 'Dime qu√© debo cantar',\n",
              " 'Oh, algoritmo',\n",
              " 'S√© que lo sabes mejor',\n",
              " 'Incluso que yo mismo',\n",
              " '[Verso 2: Jorge Drexler]',\n",
              " 'Por ejemplo, esta canci√≥n',\n",
              " '¬øQu√© algoritmo la pari√≥?',\n",
              " 'Me pregunto si fui yo',\n",
              " '¬øLa elegiste o te eligi√≥?',\n",
              " '[Verso 3: Jorge Drexler]',\n",
              " 'Dios era la letra chica al final del papel',\n",
              " 'Ya no contamos con √âl',\n",
              " 'Fin de la Luna de miel',\n",
              " 'Y el libre albedr√≠o es un cauce vac√≠o',\n",
              " 'Un barco que no tiene r√≠o',\n",
              " 'Ni timonel',\n",
              " '[Verso 4: Jorge Drexler]',\n",
              " 'Todos aplauden, t√∫ tambi√©n',\n",
              " 'Pero no queda claro qui√©n',\n",
              " 'Tiene del mango a la sart√©n',\n",
              " 'Del sacrificio',\n",
              " 'Piel o silicio',\n",
              " 'Y el precipicio',\n",
              " 'Dice: Ven, ven, ven',\n",
              " '[Refr√°n: Jorge Drexler]',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Dime qu√© debo cantar)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Oh, algoritmo)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(S√© que lo sabes mejor)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Incluso que yo mismo)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Dime qu√© debo cantar)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Oh, algoritmo)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(S√© que lo sabes mejor)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Incluso que yo mismo)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Wow)']"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "oraciones_limpias = get_sentences(texto)\n",
        "oraciones_limpias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEBzcR6Ym0Us"
      },
      "source": [
        "Deber√≠a obtener en total 87 oraciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pDN1vGEmwRQ",
        "outputId": "bdecd9e4-4d9e-4297-9319-8f938fc726ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(oraciones_limpias) == 87"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp9dq8omm7cD"
      },
      "source": [
        "Ahora definiremos el conjunto de entrenamiento y prueba para las oraciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVHoR_-inEK1",
        "outputId": "c28b779e-ab7e-4c55-b061-86701fadacba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(69, 18)"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split = int(len(oraciones_limpias) * 0.8)\n",
        "train_corpus = oraciones_limpias[:split]\n",
        "test_corpus = oraciones_limpias[split:]\n",
        "\n",
        "len(train_corpus), len(test_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csdw0qNsmjTF"
      },
      "source": [
        "### 6.b Estimaci√≥n de N-gramas (0.5 puntos)\n",
        "\n",
        "Defina una funci√≥n que reciba una lista de oraciones de un corpus y un N que indique el tama√±o de los N-gramas. La funci√≥n debe retornar un diccionario de Python donde la llave es un token (o palabra) y el valor es la cantidad de veces que ocurre el token, es decir, la frecuencia. En el caso de N-gramas con N mayor a 1 (como bi-gramas o tri-gramas) debe a√±adir un token especial al inicio o final de cada oraci√≥n seg√∫n corresponda (ver clases del curso)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "bB2_1y1etIBF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/martinbravodiaz/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "Lbrl3WVnmRzj"
      },
      "outputs": [],
      "source": [
        "def n_grams(corpus, n=3):\n",
        "      \n",
        "      # Crear un diccionario para almacenar los n-gramas\n",
        "      n_grams = {}\n",
        "  \n",
        "      # Recorrer las oraciones del corpus\n",
        "      for sentence in corpus:\n",
        "          # Tokenizar la oraci√≥n\n",
        "          tokens = word_tokenize(sentence)\n",
        "          # Recorrer los tokens\n",
        "          for i in range(len(tokens) - n + 1):\n",
        "              # Crear el n-grama\n",
        "              n_gram = \" \".join(tokens[i:i+n])\n",
        "              # Agregar el n-grama al diccionario\n",
        "              if n_gram in n_grams:\n",
        "                  n_grams[n_gram] += 1\n",
        "              else:\n",
        "                  n_grams[n_gram] = 1\n",
        "  \n",
        "      return n_grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "mAoYncsp3C7u"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'[': 10,\n",
              " 'Letra': 1,\n",
              " 'de': 3,\n",
              " '``': 1,\n",
              " '¬°Oh': 1,\n",
              " ',': 11,\n",
              " 'Algoritmo': 1,\n",
              " '!': 1,\n",
              " \"''\": 1,\n",
              " 'ft': 1,\n",
              " 'Nora': 3,\n",
              " 'Erez': 3,\n",
              " ']': 10,\n",
              " 'Refr√°n': 2,\n",
              " ':': 11,\n",
              " 'Jorge': 10,\n",
              " 'Drexler': 10,\n",
              " '¬øQui√©n': 11,\n",
              " 'quiere': 11,\n",
              " 'que': 38,\n",
              " 'yo': 14,\n",
              " 'quiera': 11,\n",
              " 'lo': 13,\n",
              " 'creo': 11,\n",
              " 'quiero': 11,\n",
              " '?': 18,\n",
              " 'Estribillo': 2,\n",
              " 'Dime': 3,\n",
              " 'qu√©': 3,\n",
              " 'debo': 3,\n",
              " 'cantar': 3,\n",
              " 'Oh': 2,\n",
              " 'algoritmo': 3,\n",
              " 'S√©': 2,\n",
              " 'sabes': 2,\n",
              " 'mejor': 2,\n",
              " 'Incluso': 2,\n",
              " 'mismo': 2,\n",
              " 'Verso': 4,\n",
              " '1': 1,\n",
              " 'Wait': 1,\n",
              " 'what': 3,\n",
              " \"'s\": 3,\n",
              " 'that': 4,\n",
              " 'money': 1,\n",
              " 'you': 6,\n",
              " 'spent': 1,\n",
              " 'What': 1,\n",
              " 'sitting': 1,\n",
              " 'on': 3,\n",
              " 'your': 1,\n",
              " 'plate': 1,\n",
              " 'Do': 1,\n",
              " 'want': 4,\n",
              " \"'ve\": 1,\n",
              " 'been': 1,\n",
              " 'fed': 1,\n",
              " 'Are': 1,\n",
              " 'the': 8,\n",
              " 'fish': 1,\n",
              " 'or': 1,\n",
              " 'bait': 1,\n",
              " 'Mmm': 1,\n",
              " 'I': 7,\n",
              " \"'m\": 2,\n",
              " 'top': 1,\n",
              " 'of': 1,\n",
              " 'roof': 1,\n",
              " 'and': 1,\n",
              " 'feel': 1,\n",
              " 'like': 3,\n",
              " 'a': 3,\n",
              " 'jail': 1,\n",
              " 'Rather': 1,\n",
              " 'not': 3,\n",
              " 'pay': 1,\n",
              " 'bail': 1,\n",
              " 'To': 1,\n",
              " 'dangerous': 1,\n",
              " 'people': 1,\n",
              " 'with': 2,\n",
              " 'blood': 1,\n",
              " 'their': 1,\n",
              " 'faces': 1,\n",
              " 'So': 2,\n",
              " 'sharing': 1,\n",
              " 'cell': 1,\n",
              " 'masses': 1,\n",
              " 'The': 1,\n",
              " 'underground': 1,\n",
              " 'always': 1,\n",
              " 'strive': 1,\n",
              " 'for': 1,\n",
              " 'main': 1,\n",
              " 'Streaming': 1,\n",
              " 'Grande': 1,\n",
              " 'big-ass': 1,\n",
              " 'ring': 1,\n",
              " 'Screaming': 1,\n",
              " \"'ll\": 1,\n",
              " 'write': 1,\n",
              " 'out': 1,\n",
              " 'my': 1,\n",
              " 'will': 3,\n",
              " 'Conscious': 2,\n",
              " 'is': 2,\n",
              " 'free': 2,\n",
              " 'but': 2,\n",
              " 'You': 1,\n",
              " 'might': 1,\n",
              " 'also': 1,\n",
              " 'Amor': 1,\n",
              " 'al': 2,\n",
              " 'Arte': 1,\n",
              " 'Tinta': 1,\n",
              " 'y': 1,\n",
              " 'Tiempo': 1,\n",
              " 'Asilo': 1,\n",
              " 'Pre-Estribillo': 1,\n",
              " 'if': 1,\n",
              " 'me': 1,\n",
              " 'to': 2,\n",
              " 'believe': 1,\n",
              " 'Can': 1,\n",
              " 'choose': 1,\n",
              " 'quit': 1,\n",
              " '2': 1,\n",
              " 'Por': 1,\n",
              " 'ejemplo': 1,\n",
              " 'esta': 1,\n",
              " 'canci√≥n': 1,\n",
              " '¬øQu√©': 1,\n",
              " 'la': 4,\n",
              " 'pari√≥': 1,\n",
              " 'Me': 1,\n",
              " 'pregunto': 1,\n",
              " 'si': 1,\n",
              " 'fui': 1,\n",
              " '¬øLa': 1,\n",
              " 'elegiste': 1,\n",
              " 'o': 2,\n",
              " 'te': 1,\n",
              " 'eligi√≥': 1,\n",
              " '3': 1,\n",
              " 'Dios': 1,\n",
              " 'era': 1,\n",
              " 'letra': 1,\n",
              " 'chica': 1,\n",
              " 'final': 1,\n",
              " 'del': 2,\n",
              " 'papel': 1,\n",
              " 'Ya': 1,\n",
              " 'no': 3,\n",
              " 'contamos': 1,\n",
              " 'con': 1,\n",
              " '√âl': 1,\n",
              " 'Fin': 1,\n",
              " 'Luna': 1,\n",
              " 'miel': 1,\n",
              " 'Y': 2,\n",
              " 'el': 2,\n",
              " 'libre': 1,\n",
              " 'albedr√≠o': 1,\n",
              " 'es': 1,\n",
              " 'un': 1,\n",
              " 'cauce': 1,\n",
              " 'vac√≠o': 1,\n",
              " 'Un': 1,\n",
              " 'barco': 1,\n",
              " 'tiene': 1,\n",
              " 'r√≠o': 1,\n",
              " 'Ni': 1,\n",
              " 'timonel': 1,\n",
              " '4': 1,\n",
              " 'Todos': 1,\n",
              " 'aplauden': 1,\n",
              " 't√∫': 1,\n",
              " 'tambi√©n': 1,\n",
              " 'Pero': 1,\n",
              " 'queda': 1,\n",
              " 'claro': 1,\n",
              " 'qui√©n': 1,\n",
              " 'Tiene': 1,\n",
              " 'mango': 1,\n",
              " 'sart√©n': 1,\n",
              " 'Del': 1,\n",
              " 'sacrificio': 1,\n",
              " 'Piel': 1,\n",
              " 'silicio': 1,\n",
              " 'precipicio': 1,\n",
              " 'Dice': 1,\n",
              " 'Ven': 1,\n",
              " 'ven': 2,\n",
              " '(': 1,\n",
              " ')': 1}"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_grams(train_corpus, n=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "A8XDEuRF3Grx"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'[ Letra': 1,\n",
              " 'Letra de': 1,\n",
              " 'de ``': 1,\n",
              " '`` ¬°Oh': 1,\n",
              " '¬°Oh ,': 1,\n",
              " ', Algoritmo': 1,\n",
              " 'Algoritmo !': 1,\n",
              " \"! ''\": 1,\n",
              " \"'' ft\": 1,\n",
              " 'ft Nora': 1,\n",
              " 'Nora Erez': 3,\n",
              " 'Erez ]': 3,\n",
              " '[ Refr√°n': 2,\n",
              " 'Refr√°n :': 2,\n",
              " ': Jorge': 7,\n",
              " 'Jorge Drexler': 10,\n",
              " 'Drexler ]': 7,\n",
              " '¬øQui√©n quiere': 11,\n",
              " 'quiere que': 11,\n",
              " 'que yo': 13,\n",
              " 'yo quiera': 11,\n",
              " 'quiera lo': 11,\n",
              " 'lo que': 11,\n",
              " 'que creo': 11,\n",
              " 'creo que': 11,\n",
              " 'que quiero': 11,\n",
              " 'quiero ?': 11,\n",
              " '[ Estribillo': 2,\n",
              " 'Estribillo :': 2,\n",
              " 'Dime qu√©': 3,\n",
              " 'qu√© debo': 3,\n",
              " 'debo cantar': 3,\n",
              " 'Oh ,': 2,\n",
              " ', algoritmo': 2,\n",
              " 'S√© que': 2,\n",
              " 'que lo': 2,\n",
              " 'lo sabes': 2,\n",
              " 'sabes mejor': 2,\n",
              " 'Incluso que': 2,\n",
              " 'yo mismo': 2,\n",
              " '[ Verso': 4,\n",
              " 'Verso 1': 1,\n",
              " '1 :': 1,\n",
              " ': Nora': 2,\n",
              " 'Wait ,': 1,\n",
              " ', what': 1,\n",
              " \"what 's\": 1,\n",
              " \"'s that\": 2,\n",
              " 'that money': 1,\n",
              " 'money that': 1,\n",
              " 'that you': 1,\n",
              " 'you spent': 1,\n",
              " 'spent ?': 1,\n",
              " \"What 's\": 1,\n",
              " 'that sitting': 1,\n",
              " 'sitting on': 1,\n",
              " 'on your': 1,\n",
              " 'your plate': 1,\n",
              " 'plate ?': 1,\n",
              " 'Do you': 1,\n",
              " 'you want': 2,\n",
              " 'want what': 2,\n",
              " 'what you': 1,\n",
              " \"you 've\": 1,\n",
              " \"'ve been\": 1,\n",
              " 'been fed': 1,\n",
              " 'fed ?': 1,\n",
              " 'Are you': 1,\n",
              " 'you the': 1,\n",
              " 'the fish': 1,\n",
              " 'fish or': 1,\n",
              " 'or bait': 1,\n",
              " 'bait ?': 1,\n",
              " 'Mmm ,': 1,\n",
              " ', I': 1,\n",
              " \"I 'm\": 2,\n",
              " \"'m on\": 1,\n",
              " 'on the': 1,\n",
              " 'the top': 1,\n",
              " 'top of': 1,\n",
              " 'of the': 1,\n",
              " 'the roof': 1,\n",
              " 'roof and': 1,\n",
              " 'and I': 1,\n",
              " 'I feel': 1,\n",
              " 'feel like': 1,\n",
              " 'like a': 1,\n",
              " 'a jail': 1,\n",
              " 'Rather not': 1,\n",
              " 'not pay': 1,\n",
              " 'pay the': 1,\n",
              " 'the bail': 1,\n",
              " 'To dangerous': 1,\n",
              " 'dangerous people': 1,\n",
              " 'people with': 1,\n",
              " 'with blood': 1,\n",
              " 'blood on': 1,\n",
              " 'on their': 1,\n",
              " 'their faces': 1,\n",
              " 'So I': 1,\n",
              " \"'m sharing\": 1,\n",
              " 'sharing a': 1,\n",
              " 'a cell': 1,\n",
              " 'cell with': 1,\n",
              " 'with the': 1,\n",
              " 'the masses': 1,\n",
              " 'The underground': 1,\n",
              " 'underground always': 1,\n",
              " 'always strive': 1,\n",
              " 'strive for': 1,\n",
              " 'for the': 1,\n",
              " 'the main': 1,\n",
              " 'Streaming like': 1,\n",
              " 'like Grande': 1,\n",
              " \"Grande 's\": 1,\n",
              " \"'s big-ass\": 1,\n",
              " 'big-ass ring': 1,\n",
              " 'Screaming :': 1,\n",
              " ': I': 1,\n",
              " \"I 'll\": 1,\n",
              " \"'ll write\": 1,\n",
              " 'write you': 1,\n",
              " 'you out': 1,\n",
              " 'out my': 1,\n",
              " 'my will': 1,\n",
              " 'Conscious is': 2,\n",
              " 'is free': 2,\n",
              " 'free ,': 2,\n",
              " ', but': 2,\n",
              " 'but not': 2,\n",
              " 'not the': 2,\n",
              " 'the will': 2,\n",
              " 'You might': 1,\n",
              " 'might also': 1,\n",
              " 'also like': 1,\n",
              " 'Amor al': 1,\n",
              " 'al Arte': 1,\n",
              " 'Tinta y': 1,\n",
              " 'y Tiempo': 1,\n",
              " '[ Pre-Estribillo': 1,\n",
              " 'Pre-Estribillo :': 1,\n",
              " 'So if': 1,\n",
              " 'if you': 1,\n",
              " 'want me': 1,\n",
              " 'me to': 1,\n",
              " 'to want': 1,\n",
              " 'what I': 1,\n",
              " 'I believe': 1,\n",
              " 'believe that': 1,\n",
              " 'that I': 1,\n",
              " 'I want': 1,\n",
              " 'Can I': 1,\n",
              " 'I choose': 1,\n",
              " 'choose to': 1,\n",
              " 'to quit': 1,\n",
              " 'quit ?': 1,\n",
              " 'Verso 2': 1,\n",
              " '2 :': 1,\n",
              " 'Por ejemplo': 1,\n",
              " 'ejemplo ,': 1,\n",
              " ', esta': 1,\n",
              " 'esta canci√≥n': 1,\n",
              " '¬øQu√© algoritmo': 1,\n",
              " 'algoritmo la': 1,\n",
              " 'la pari√≥': 1,\n",
              " 'pari√≥ ?': 1,\n",
              " 'Me pregunto': 1,\n",
              " 'pregunto si': 1,\n",
              " 'si fui': 1,\n",
              " 'fui yo': 1,\n",
              " '¬øLa elegiste': 1,\n",
              " 'elegiste o': 1,\n",
              " 'o te': 1,\n",
              " 'te eligi√≥': 1,\n",
              " 'eligi√≥ ?': 1,\n",
              " 'Verso 3': 1,\n",
              " '3 :': 1,\n",
              " 'Dios era': 1,\n",
              " 'era la': 1,\n",
              " 'la letra': 1,\n",
              " 'letra chica': 1,\n",
              " 'chica al': 1,\n",
              " 'al final': 1,\n",
              " 'final del': 1,\n",
              " 'del papel': 1,\n",
              " 'Ya no': 1,\n",
              " 'no contamos': 1,\n",
              " 'contamos con': 1,\n",
              " 'con √âl': 1,\n",
              " 'Fin de': 1,\n",
              " 'de la': 1,\n",
              " 'la Luna': 1,\n",
              " 'Luna de': 1,\n",
              " 'de miel': 1,\n",
              " 'Y el': 2,\n",
              " 'el libre': 1,\n",
              " 'libre albedr√≠o': 1,\n",
              " 'albedr√≠o es': 1,\n",
              " 'es un': 1,\n",
              " 'un cauce': 1,\n",
              " 'cauce vac√≠o': 1,\n",
              " 'Un barco': 1,\n",
              " 'barco que': 1,\n",
              " 'que no': 1,\n",
              " 'no tiene': 1,\n",
              " 'tiene r√≠o': 1,\n",
              " 'Ni timonel': 1,\n",
              " 'Verso 4': 1,\n",
              " '4 :': 1,\n",
              " 'Todos aplauden': 1,\n",
              " 'aplauden ,': 1,\n",
              " ', t√∫': 1,\n",
              " 't√∫ tambi√©n': 1,\n",
              " 'Pero no': 1,\n",
              " 'no queda': 1,\n",
              " 'queda claro': 1,\n",
              " 'claro qui√©n': 1,\n",
              " 'Tiene del': 1,\n",
              " 'del mango': 1,\n",
              " 'mango a': 1,\n",
              " 'a la': 1,\n",
              " 'la sart√©n': 1,\n",
              " 'Del sacrificio': 1,\n",
              " 'Piel o': 1,\n",
              " 'o silicio': 1,\n",
              " 'el precipicio': 1,\n",
              " 'Dice :': 1,\n",
              " ': Ven': 1,\n",
              " 'Ven ,': 1,\n",
              " ', ven': 2,\n",
              " 'ven ,': 1,\n",
              " '( Dime': 1,\n",
              " 'cantar )': 1}"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_grams(train_corpus, n=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "jCpbhiXp3Gpg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'[ Letra de': 1,\n",
              " 'Letra de ``': 1,\n",
              " 'de `` ¬°Oh': 1,\n",
              " '`` ¬°Oh ,': 1,\n",
              " '¬°Oh , Algoritmo': 1,\n",
              " ', Algoritmo !': 1,\n",
              " \"Algoritmo ! ''\": 1,\n",
              " \"! '' ft\": 1,\n",
              " \"'' ft Nora\": 1,\n",
              " 'ft Nora Erez': 1,\n",
              " 'Nora Erez ]': 3,\n",
              " '[ Refr√°n :': 2,\n",
              " 'Refr√°n : Jorge': 2,\n",
              " ': Jorge Drexler': 7,\n",
              " 'Jorge Drexler ]': 7,\n",
              " '¬øQui√©n quiere que': 11,\n",
              " 'quiere que yo': 11,\n",
              " 'que yo quiera': 11,\n",
              " 'yo quiera lo': 11,\n",
              " 'quiera lo que': 11,\n",
              " 'lo que creo': 11,\n",
              " 'que creo que': 11,\n",
              " 'creo que quiero': 11,\n",
              " 'que quiero ?': 11,\n",
              " '[ Estribillo :': 2,\n",
              " 'Estribillo : Jorge': 2,\n",
              " 'Dime qu√© debo': 3,\n",
              " 'qu√© debo cantar': 3,\n",
              " 'Oh , algoritmo': 2,\n",
              " 'S√© que lo': 2,\n",
              " 'que lo sabes': 2,\n",
              " 'lo sabes mejor': 2,\n",
              " 'Incluso que yo': 2,\n",
              " 'que yo mismo': 2,\n",
              " '[ Verso 1': 1,\n",
              " 'Verso 1 :': 1,\n",
              " '1 : Nora': 1,\n",
              " ': Nora Erez': 2,\n",
              " 'Wait , what': 1,\n",
              " \", what 's\": 1,\n",
              " \"what 's that\": 1,\n",
              " \"'s that money\": 1,\n",
              " 'that money that': 1,\n",
              " 'money that you': 1,\n",
              " 'that you spent': 1,\n",
              " 'you spent ?': 1,\n",
              " \"What 's that\": 1,\n",
              " \"'s that sitting\": 1,\n",
              " 'that sitting on': 1,\n",
              " 'sitting on your': 1,\n",
              " 'on your plate': 1,\n",
              " 'your plate ?': 1,\n",
              " 'Do you want': 1,\n",
              " 'you want what': 1,\n",
              " 'want what you': 1,\n",
              " \"what you 've\": 1,\n",
              " \"you 've been\": 1,\n",
              " \"'ve been fed\": 1,\n",
              " 'been fed ?': 1,\n",
              " 'Are you the': 1,\n",
              " 'you the fish': 1,\n",
              " 'the fish or': 1,\n",
              " 'fish or bait': 1,\n",
              " 'or bait ?': 1,\n",
              " 'Mmm , I': 1,\n",
              " \", I 'm\": 1,\n",
              " \"I 'm on\": 1,\n",
              " \"'m on the\": 1,\n",
              " 'on the top': 1,\n",
              " 'the top of': 1,\n",
              " 'top of the': 1,\n",
              " 'of the roof': 1,\n",
              " 'the roof and': 1,\n",
              " 'roof and I': 1,\n",
              " 'and I feel': 1,\n",
              " 'I feel like': 1,\n",
              " 'feel like a': 1,\n",
              " 'like a jail': 1,\n",
              " 'Rather not pay': 1,\n",
              " 'not pay the': 1,\n",
              " 'pay the bail': 1,\n",
              " 'To dangerous people': 1,\n",
              " 'dangerous people with': 1,\n",
              " 'people with blood': 1,\n",
              " 'with blood on': 1,\n",
              " 'blood on their': 1,\n",
              " 'on their faces': 1,\n",
              " \"So I 'm\": 1,\n",
              " \"I 'm sharing\": 1,\n",
              " \"'m sharing a\": 1,\n",
              " 'sharing a cell': 1,\n",
              " 'a cell with': 1,\n",
              " 'cell with the': 1,\n",
              " 'with the masses': 1,\n",
              " 'The underground always': 1,\n",
              " 'underground always strive': 1,\n",
              " 'always strive for': 1,\n",
              " 'strive for the': 1,\n",
              " 'for the main': 1,\n",
              " 'Streaming like Grande': 1,\n",
              " \"like Grande 's\": 1,\n",
              " \"Grande 's big-ass\": 1,\n",
              " \"'s big-ass ring\": 1,\n",
              " 'Screaming : I': 1,\n",
              " \": I 'll\": 1,\n",
              " \"I 'll write\": 1,\n",
              " \"'ll write you\": 1,\n",
              " 'write you out': 1,\n",
              " 'you out my': 1,\n",
              " 'out my will': 1,\n",
              " 'Conscious is free': 2,\n",
              " 'is free ,': 2,\n",
              " 'free , but': 2,\n",
              " ', but not': 2,\n",
              " 'but not the': 2,\n",
              " 'not the will': 2,\n",
              " 'You might also': 1,\n",
              " 'might also like': 1,\n",
              " 'Amor al Arte': 1,\n",
              " 'Tinta y Tiempo': 1,\n",
              " '[ Pre-Estribillo :': 1,\n",
              " 'Pre-Estribillo : Nora': 1,\n",
              " 'So if you': 1,\n",
              " 'if you want': 1,\n",
              " 'you want me': 1,\n",
              " 'want me to': 1,\n",
              " 'me to want': 1,\n",
              " 'to want what': 1,\n",
              " 'want what I': 1,\n",
              " 'what I believe': 1,\n",
              " 'I believe that': 1,\n",
              " 'believe that I': 1,\n",
              " 'that I want': 1,\n",
              " 'Can I choose': 1,\n",
              " 'I choose to': 1,\n",
              " 'choose to quit': 1,\n",
              " 'to quit ?': 1,\n",
              " '[ Verso 2': 1,\n",
              " 'Verso 2 :': 1,\n",
              " '2 : Jorge': 1,\n",
              " 'Por ejemplo ,': 1,\n",
              " 'ejemplo , esta': 1,\n",
              " ', esta canci√≥n': 1,\n",
              " '¬øQu√© algoritmo la': 1,\n",
              " 'algoritmo la pari√≥': 1,\n",
              " 'la pari√≥ ?': 1,\n",
              " 'Me pregunto si': 1,\n",
              " 'pregunto si fui': 1,\n",
              " 'si fui yo': 1,\n",
              " '¬øLa elegiste o': 1,\n",
              " 'elegiste o te': 1,\n",
              " 'o te eligi√≥': 1,\n",
              " 'te eligi√≥ ?': 1,\n",
              " '[ Verso 3': 1,\n",
              " 'Verso 3 :': 1,\n",
              " '3 : Jorge': 1,\n",
              " 'Dios era la': 1,\n",
              " 'era la letra': 1,\n",
              " 'la letra chica': 1,\n",
              " 'letra chica al': 1,\n",
              " 'chica al final': 1,\n",
              " 'al final del': 1,\n",
              " 'final del papel': 1,\n",
              " 'Ya no contamos': 1,\n",
              " 'no contamos con': 1,\n",
              " 'contamos con √âl': 1,\n",
              " 'Fin de la': 1,\n",
              " 'de la Luna': 1,\n",
              " 'la Luna de': 1,\n",
              " 'Luna de miel': 1,\n",
              " 'Y el libre': 1,\n",
              " 'el libre albedr√≠o': 1,\n",
              " 'libre albedr√≠o es': 1,\n",
              " 'albedr√≠o es un': 1,\n",
              " 'es un cauce': 1,\n",
              " 'un cauce vac√≠o': 1,\n",
              " 'Un barco que': 1,\n",
              " 'barco que no': 1,\n",
              " 'que no tiene': 1,\n",
              " 'no tiene r√≠o': 1,\n",
              " '[ Verso 4': 1,\n",
              " 'Verso 4 :': 1,\n",
              " '4 : Jorge': 1,\n",
              " 'Todos aplauden ,': 1,\n",
              " 'aplauden , t√∫': 1,\n",
              " ', t√∫ tambi√©n': 1,\n",
              " 'Pero no queda': 1,\n",
              " 'no queda claro': 1,\n",
              " 'queda claro qui√©n': 1,\n",
              " 'Tiene del mango': 1,\n",
              " 'del mango a': 1,\n",
              " 'mango a la': 1,\n",
              " 'a la sart√©n': 1,\n",
              " 'Piel o silicio': 1,\n",
              " 'Y el precipicio': 1,\n",
              " 'Dice : Ven': 1,\n",
              " ': Ven ,': 1,\n",
              " 'Ven , ven': 1,\n",
              " ', ven ,': 1,\n",
              " 'ven , ven': 1,\n",
              " '( Dime qu√©': 1,\n",
              " 'debo cantar )': 1}"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_grams(train_corpus, n=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHgEpVPj21fs"
      },
      "source": [
        "Debe mostrar que su m√©todo funciona para $N = 1,2,3$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMzLfBLBk-i7"
      },
      "source": [
        "## P7. Perplexity (1 punto)\n",
        "\n",
        "En esta secci√≥n evaluar√°n su modelo de n-gramas y determinar√°n la probabilidad de oraciones y la perplejidad con un conjunto de test. Recuerde que la perplejidad se define de la siguiente manera:\n",
        "\n",
        "$$\n",
        "\\text{Perplexity} = 2^{-l} \\quad \\quad l = \\frac{1}{M} \\sum_{i=1}^{m} \\log p(s_i)\n",
        "$$\n",
        "\n",
        "con $m$ el n√∫mero de oraciones del corpus y $M$ el tama√±o del vocabulario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tas4KYhZ28_C"
      },
      "source": [
        "### 7.a Obtener probabilidades (0.5 puntos)\n",
        "\n",
        "En esta secci√≥n implementar√° una funci√≥n que determine la probabilidad de una oraci√≥n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYH0ScM44Jrb"
      },
      "source": [
        "Defina una funci√≥n que reciba una oraci√≥n, un diccionario con n-gramas y el valor de $n$. La funci√≥n debe entregar la probabilidad de cualquier oraci√≥n.\n",
        "\n",
        "**Hint**: No olvide los posibles casos borde, como palabras fuera del vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "aWGsq22H4Sxz"
      },
      "outputs": [],
      "source": [
        "def get_probability(sentence, n_grams_frequency, n):\n",
        "  \n",
        "    # Extraer tokens de la oraci√≥n\n",
        "    sentence_tokens = word_tokenize(sentence)\n",
        "    # Crear n-gramas\n",
        "    n_grams_sentence = [sentence_tokens[i:i+n] for i in range(len(sentence_tokens) - n + 1)]\n",
        "    # Convertir n-gramas a cadenas\n",
        "    n_grams_sentence = [\" \".join(n_gram) for n_gram in n_grams_sentence]\n",
        "    # Calcular la probabilidad\n",
        "    probability = 0\n",
        "    for n_gram in n_grams_sentence:\n",
        "        if n_gram in n_grams_frequency:\n",
        "            probability += n_grams_frequency[n_gram] / sum(n_grams_frequency.values())\n",
        "\n",
        "    return probability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1UkfOz75W_P"
      },
      "source": [
        "Pruebe su funci√≥n con oraciones frecuentes y comente sus resultados\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "7ITfzYJx5fqV"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.010126582278481013"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_probability(\"Oh, algoritmo\", n_grams(train_corpus, n=2), 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfnIFV7F3eOL"
      },
      "source": [
        "### 7.b Perplexity en conjunto de test (0.5 puntos)\n",
        "\n",
        "En esta sub-secci√≥n deber√° calcular la perplejidad del corpus de test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N21I_mPl5Cqx"
      },
      "source": [
        "Defina una funci√≥n que reciba un corpus de test y retorne la perplexity (ver clases del curso). Utilice la funci√≥n de la secci√≥n anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "VC4Vbk3q5LsY"
      },
      "outputs": [],
      "source": [
        "def get_perplexity(corpus, n):\n",
        "\n",
        "  # Obtener el largo del vocabulario\n",
        "  vocab = get_vocab(corpus)\n",
        "  M = len(vocab)\n",
        "\n",
        "  # Obtener el largo de las oraciones\n",
        "  m = len(corpus)\n",
        "\n",
        "  # Calcular la sumatoria \n",
        "  sum = 0\n",
        "  for i in range(m):\n",
        "    sum += np.log(get_probability(corpus[i], n_grams(corpus, n), n))\n",
        "  l = sum / M\n",
        "\n",
        "  # Calcular la perplexity\n",
        "  perplexity = 2 ** (-l)\n",
        "\n",
        "  return perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['(Oh, algoritmo)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(S√© que lo sabes mejor)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Incluso que yo mismo)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Dime qu√© debo cantar)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Oh, algoritmo)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(S√© que lo sabes mejor)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Incluso que yo mismo)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Wow)']"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "OAjpRDoG5sUJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.2082530160514944"
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_perplexity(test_corpus, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhc07wXM5gyI"
      },
      "source": [
        "D√© una interpretacion de la perplexity en el corpus de test:\n",
        "```\n",
        "Nosotros \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYNsmR4OPQQX"
      },
      "source": [
        "## P8. Interpolaci√≥n Lineal (0.5 puntos)\n",
        "\n",
        "Cree una funci√≥n que obtenga la probabilidad de una oraci√≥n interpolando linealmente modelos de unigrama, bigrama y trigrama ponderados por $\\lambda_1, \\lambda_2$ y $\\lambda_3$ respectivamente. Para esto use las funciones que cre√≥ anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "X7kcWusAPPv5"
      },
      "outputs": [],
      "source": [
        "def get_probability_lineal_interpol(sentence, corpus, l_1, l_2, l_3):\n",
        "  \n",
        "    # Calcular la probabilidad\n",
        "    probability = 0\n",
        "    for i in range(1, 4):\n",
        "      probability += get_probability(sentence, n_grams(corpus, i), i) * [l_1, l_2, l_3][i-1]\n",
        "\n",
        "    return probability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO1J_E77RQp3"
      },
      "source": [
        "Defina una funci√≥n para calcular la perplejidad de un corpus con interpolaci√≥n lineal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "oAS94E1UROkg"
      },
      "outputs": [],
      "source": [
        "def get_pp_interpol(corpus, l_1, l_2, l_3):\n",
        "  \n",
        "    # Obtener el largo del vocabulario\n",
        "    vocab = get_vocab(corpus)\n",
        "    M = len(vocab)\n",
        "\n",
        "    # Obtener el largo de las oraciones\n",
        "    m = len(corpus)\n",
        "\n",
        "    # Calcular la sumatoria \n",
        "    sum = 0\n",
        "    for i in range(m):\n",
        "      sum += np.log(get_probability_lineal_interpol(corpus[i], corpus, l_1, l_2, l_3))\n",
        "    l = sum / M\n",
        "\n",
        "    # Calcular la perplexity\n",
        "    perplexity = 2 ** (-l)\n",
        "\n",
        "    return perplexity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqoX9_o2SHOY"
      },
      "source": [
        "Ahora haga pruebas con distintos valores de $\\lambda_1, \\lambda_2$ y $\\lambda_3$, incluyendo valores extremos (por ejemplo $[1, 0, 0]$). Comente sus resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "0PZ2UvohRsvJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0695087602131068"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_pp_interpol(test_corpus, 1, 0, 0)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
